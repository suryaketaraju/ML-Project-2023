{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\nimport os\nimport torch\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:07:12.063627Z","iopub.execute_input":"2023-11-09T15:07:12.064314Z","iopub.status.idle":"2023-11-09T15:07:36.514127Z","shell.execute_reply.started":"2023-11-09T15:07:12.064274Z","shell.execute_reply":"2023-11-09T15:07:36.513306Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize GPT-2 tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.mask_token = None  # Set the mask token to None\n\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:07:38.982137Z","iopub.execute_input":"2023-11-09T15:07:38.982932Z","iopub.status.idle":"2023-11-09T15:07:45.736685Z","shell.execute_reply.started":"2023-11-09T15:07:38.982894Z","shell.execute_reply":"2023-11-09T15:07:45.735610Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e364e29d8c4454880d5d7295306012f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3a1e053a9f4544886e71807b2cbf4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43da7bbd9e674a31bb036d8a767d12e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09f481ea48441f3b7d9a8016b1b911e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21d55266c4454d5ebf294b768c31cf00"}},"metadata":{}}]},{"cell_type":"code","source":"\n# Load and process the Ramayana text data\nramayana_text_file = '/kaggle/input/sampurna-ramayanam/ramayana.txt'  # Replace with your dataset file path\n\nwith open(ramayana_text_file, 'r', encoding='utf-8') as file:\n    ramayana_text = file.read()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:07:47.422535Z","iopub.execute_input":"2023-11-09T15:07:47.423195Z","iopub.status.idle":"2023-11-09T15:07:47.498719Z","shell.execute_reply.started":"2023-11-09T15:07:47.423158Z","shell.execute_reply":"2023-11-09T15:07:47.497863Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n# Define the directory for training files\ntraining_dir = '/kaggle/working/' # Replace with your desired directory\nos.makedirs(training_dir, exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:07:50.008313Z","iopub.execute_input":"2023-11-09T15:07:50.008769Z","iopub.status.idle":"2023-11-09T15:07:50.015019Z","shell.execute_reply.started":"2023-11-09T15:07:50.008732Z","shell.execute_reply":"2023-11-09T15:07:50.013835Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n# Save the Ramayana text as a training file\ntraining_file_path = os.path.join(training_dir, 'ramayana.txt')\nwith open(training_file_path, 'w', encoding='utf-8') as file:\n    file.write(ramayana_text)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:08:10.550336Z","iopub.execute_input":"2023-11-09T15:08:10.550720Z","iopub.status.idle":"2023-11-09T15:08:10.566444Z","shell.execute_reply.started":"2023-11-09T15:08:10.550682Z","shell.execute_reply":"2023-11-09T15:08:10.565438Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# Create a TextDataset\ntrain_dataset = TextDataset(\n    tokenizer=tokenizer,\n    file_path=training_file_path,\n    block_size=128  # Adjust the block_size according to your data length\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:08:12.742628Z","iopub.execute_input":"2023-11-09T15:08:12.743056Z","iopub.status.idle":"2023-11-09T15:08:24.925929Z","shell.execute_reply.started":"2023-11-09T15:08:12.743013Z","shell.execute_reply":"2023-11-09T15:08:24.924786Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./ramayana_model\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir='./logs',\n    prediction_loss_only=True,\n    report_to=\"none\")\n   \n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:08:24.928077Z","iopub.execute_input":"2023-11-09T15:08:24.928665Z","iopub.status.idle":"2023-11-09T15:08:25.005461Z","shell.execute_reply.started":"2023-11-09T15:08:24.928630Z","shell.execute_reply":"2023-11-09T15:08:25.004300Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n# Create a Trainer instance\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n    train_dataset=train_dataset\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:08:25.007066Z","iopub.execute_input":"2023-11-09T15:08:25.007429Z","iopub.status.idle":"2023-11-09T15:08:33.222110Z","shell.execute_reply.started":"2023-11-09T15:08:25.007396Z","shell.execute_reply":"2023-11-09T15:08:33.221066Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n# Start training the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:08:37.120270Z","iopub.execute_input":"2023-11-09T15:08:37.121166Z","iopub.status.idle":"2023-11-09T15:49:46.039805Z","shell.execute_reply.started":"2023-11-09T15:08:37.121130Z","shell.execute_reply":"2023-11-09T15:49:46.038845Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8169' max='8169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8169/8169 41:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.531400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.355700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.282400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.232400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.198100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.168200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.148400</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.130600</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.119000</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.109800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.101400</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.079300</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.083700</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.076200</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.069500</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.068600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8169, training_loss=1.1701064206115297, metrics={'train_runtime': 2468.6107, 'train_samples_per_second': 26.471, 'train_steps_per_second': 3.309, 'total_flos': 4268597280768000.0, 'train_loss': 1.1701064206115297, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
