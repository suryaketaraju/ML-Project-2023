{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6974755,"sourceType":"datasetVersion","datasetId":3958463},{"sourceId":7072708,"sourceType":"datasetVersion","datasetId":4073315},{"sourceId":7106750,"sourceType":"datasetVersion","datasetId":4097215}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\nimport os\nimport torch\n\n# Load tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token  # Assign end-of-text as the padding token\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n\n# Load and process the Ramayana text data\nramayana_train_file = '/kaggle/input/ramayana-processed/ramayana train.txt'  \n\nwith open(ramayana_train_file, 'r', encoding='utf-8') as file:\n    ramayana_text = file.readlines()\n\nvalidation_file_path = '/kaggle/input/ramayana-processed/validation.txt'  \n\nwith open(validation_file_path, 'r', encoding='utf-8') as file:\n    validation_text = file.read()\n\nvalidation_dir = '/kaggle/working/validation/'  \nos.makedirs(validation_dir, exist_ok=True)\n\nvalidation_file_path = os.path.join(validation_dir, 'validation_ramayana.txt')\nwith open(validation_file_path, 'w', encoding='utf-8') as file:\n    file.write(validation_text)","metadata":{"_uuid":"64eb4a04-eb72-402d-ac52-ed0680343b69","_cell_guid":"50ce5edd-e8e2-4a74-8a6d-be737722683c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-03T13:31:13.294998Z","iopub.execute_input":"2023-12-03T13:31:13.295844Z","iopub.status.idle":"2023-12-03T13:31:54.901813Z","shell.execute_reply.started":"2023-12-03T13:31:13.295800Z","shell.execute_reply":"2023-12-03T13:31:54.900981Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90e777fdba71487f99d7a2e5dc134122"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f1f81dbfca847b4bcc5eaf38e77f1ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bca1c2540d5548cda11d24686b4736b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c88a1a4e60174beda5603f409847a5aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b828032a4b416c92f6b4ef159067ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"476ec9f0665143ad9407aaf3f4cf1ba5"}},"metadata":{}}]},{"cell_type":"code","source":"\nclass RamayanaDataset(torch.utils.data.Dataset):\n    def __init__(self, tokenizer, data):\n        self.examples = tokenizer.batch_encode_plus(\n            data,\n            padding=\"max_length\",\n            max_length=130,\n            truncation=True,\n            return_tensors=\"pt\"  # This parameter generates PyTorch tensors\n        )\n\n        # Move tensors to CUDA\n        self.examples = {key: value.to('cuda') for key, value in self.examples.items()}\n\n    # Other methods of the class...\n\n\n    def __len__(self):\n        return len(self.examples[\"input_ids\"])\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": self.examples[\"input_ids\"][idx],\n            \"labels\": self.examples[\"input_ids\"][idx].clone()  # For language modeling tasks\n        }\n\ntrain_dataset = RamayanaDataset(tokenizer, ramayana_text)","metadata":{"_uuid":"735501a2-3ae6-485c-bea0-2dcd068c6f01","_cell_guid":"b56ba70e-fec8-4962-a65c-56a9a3aa41cc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-03T13:31:55.631510Z","iopub.execute_input":"2023-12-03T13:31:55.632191Z","iopub.status.idle":"2023-12-03T13:32:15.233458Z","shell.execute_reply.started":"2023-12-03T13:31:55.632158Z","shell.execute_reply":"2023-12-03T13:32:15.232667Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n\ntraining_args = TrainingArguments(\n    output_dir=\"./ramayana_model\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir='./logs',\n    prediction_loss_only=True,\n    report_to=\"none\",\n    eval_steps=500,  \n    evaluation_strategy=\"steps\"\n)","metadata":{"_uuid":"1f1114e1-f16b-4525-af43-41accaf1c600","_cell_guid":"e61fb502-85fd-41cf-846a-949d58efb964","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-03T13:32:26.101353Z","iopub.execute_input":"2023-12-03T13:32:26.102149Z","iopub.status.idle":"2023-12-03T13:32:26.109115Z","shell.execute_reply.started":"2023-12-03T13:32:26.102116Z","shell.execute_reply":"2023-12-03T13:32:26.107998Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nimport pickle\n#pickle.dump(rf,open(\"rf.h5\",\"wb\"))\n\nmodel = pickle.load(open(\"/kaggle/input/samskrta/samskrta.h5\",\"rb\"))\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n    train_dataset=train_dataset,\n    eval_dataset=RamayanaDataset(tokenizer, [validation_text])  # Use the validation text as a single example\n)","metadata":{"_uuid":"6606a9cd-1b67-4b4a-8045-9f18787e273d","_cell_guid":"628fe321-b509-4b73-b316-51bcf32b135e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-03T13:32:29.511389Z","iopub.execute_input":"2023-12-03T13:32:29.512288Z","iopub.status.idle":"2023-12-03T13:32:35.137826Z","shell.execute_reply.started":"2023-12-03T13:32:29.512253Z","shell.execute_reply":"2023-12-03T13:32:35.137057Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"_uuid":"e3ad8853-54c5-4027-b80f-e3681fd816d1","_cell_guid":"42396f65-762a-4314-9409-b1f0dd8722b7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-03T13:32:35.139308Z","iopub.execute_input":"2023-12-03T13:32:35.139590Z","iopub.status.idle":"2023-12-03T13:32:35.143578Z","shell.execute_reply.started":"2023-12-03T13:32:35.139564Z","shell.execute_reply":"2023-12-03T13:32:35.142701Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Move input_ids tensor to CUDA","metadata":{"_uuid":"9ce08d6d-c0ab-43af-86b0-f2b93e742338","_cell_guid":"16c6ace6-073d-4f76-bfc6-4f8164ab6881","collapsed":false,"execution":{"iopub.status.busy":"2023-12-03T11:05:43.696259Z","iopub.execute_input":"2023-12-03T11:05:43.697153Z","iopub.status.idle":"2023-12-03T11:05:43.701147Z","shell.execute_reply.started":"2023-12-03T11:05:43.697119Z","shell.execute_reply":"2023-12-03T11:05:43.700326Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_prompt =  \"तपःस्वाध्यायनिरतं \"\n\n# Tokenize the text prompt\ninput_ids = tokenizer.encode(text_prompt, return_tensors=\"pt\")\ninput_ids = input_ids.to('cuda')\n\n# Ensure attention_mask is set for reliable results\nattention_mask = torch.ones_like(input_ids)\n\n# Generate predictions\nwith torch.no_grad():\n    output = model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        max_length=130,\n        temperature=1.35,\n        pad_token_id=tokenizer.eos_token_id  # Set pad_token_id to eos_token_id\n    )","metadata":{"_uuid":"63eec24e-631c-4620-ba81-8e26e5296c8a","_cell_guid":"99b93be2-1dee-4d85-8d2f-7e90e5cd37bf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-03T13:32:41.311666Z","iopub.execute_input":"2023-12-03T13:32:41.312404Z","iopub.status.idle":"2023-12-03T13:32:45.455047Z","shell.execute_reply.started":"2023-12-03T13:32:41.312374Z","shell.execute_reply":"2023-12-03T13:32:45.453977Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.35` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the generated output tensor to a list of integers\noutput_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\n# Print the generated text\nprint(output_text)","metadata":{"_uuid":"e1e687c5-a7b2-4ed9-9b80-54182efa2e5c","_cell_guid":"1161871d-ef69-421a-b035-db3ee1bc33b1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-03T13:33:01.047572Z","iopub.execute_input":"2023-12-03T13:33:01.048424Z","iopub.status.idle":"2023-12-03T13:33:01.057527Z","shell.execute_reply.started":"2023-12-03T13:33:01.048388Z","shell.execute_reply":"2023-12-03T13:33:01.056406Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"तपःस्वाध्यायनिरतं ्यं सर्वं समरे स्थितम्\n\nयथा सह सीतां विश्रम्\n\nयम्\n\nयम्\n\nयम्\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#Downloaded the trained model with its weights\nimport pickle\n\nPkl_Filename = \"samskrta ocr.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)\n\n from IPython.display import FileLink  \n\nFileLink(r'samskrta.h5')","metadata":{"_uuid":"50d68f2e-075e-4294-bbe9-3a23472dcace","_cell_guid":"fc3e6eca-d510-425b-ba02-dc61fb70cc65","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}